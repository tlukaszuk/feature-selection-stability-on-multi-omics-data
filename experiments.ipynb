{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "datasets = {\n",
    "    name: pd.read_csv(f'datasets/{name}.csv')\n",
    "    for name in [\"BLCA\", \"BRCA\", \"COAD\"]\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name}\\t: {df.shape}\")\n",
    "\n",
    "\n",
    "def omics_str(omics):\n",
    "    if type(omics) == str:\n",
    "        omics = set([omics])\n",
    "    return reduce(lambda a,b: a+\"_\"+b, omics)\n",
    "\n",
    "def get_X(df, omics):\n",
    "    if type(omics) == str:\n",
    "        if omics == \"__ALL__\":\n",
    "            return df.values\n",
    "        omics = set([omics])\n",
    "    indexes = [\n",
    "        i\n",
    "        for i, name in enumerate(df.columns)\n",
    "        if name.split(\"_\")[-1] in omics\n",
    "    ]\n",
    "    #print(f\"selected {len(indexes)} for omics: {omics}\")\n",
    "    return df.values[:, indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set, Dict\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from utils import stability_measure\n",
    "\n",
    "\n",
    "estimators = {\n",
    "    \"LR\": (LogisticRegression, {'penalty':'l1', 'solver':'liblinear', 'max_iter':100000}),\n",
    "    \"SVM\": (LinearSVC, {'penalty':\"l1\", 'dual':False, 'max_iter':100000}),\n",
    "}\n",
    "\n",
    "\n",
    "class CVResult:\n",
    "    def __init__(self, n_features:int):\n",
    "        self.n_features = n_features # number of all features\n",
    "        self.metrics = {\n",
    "            \"accuracy\": accuracy_score\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.features_sets = []\n",
    "    \n",
    "    def add_feature_set(self, feature_set:Set[int]):\n",
    "        self.features_sets.append(feature_set)\n",
    "\n",
    "    def evaluate(self, prefix:str, y_real:List[float], y_predict:List[float]):\n",
    "        for name, fun in self.metrics.items():\n",
    "            key = f\"{prefix}_{name}\"\n",
    "            if key not in self.results:\n",
    "                self.results[key] = []\n",
    "            self.results[key].append(fun(y_real,y_predict))\n",
    "    \n",
    "    def summary(self)->Dict[str,float]:\n",
    "        results = {key:mean(values) for key, values in self.results.items()}\n",
    "        results[\"fss_nogueira\"] = stability_measure.nogueira(self.features_sets, self.n_features)\n",
    "        #results[\"fss_lustgarten\"] = stability_measure.lustgarten(self.features_sets, self.n_features)\n",
    "        results[\"avg_features\"] = mean([len(s) for s in self.features_sets])\n",
    "        results[\"all_features\"] = self.n_features\n",
    "        results[\"runs\"] = len(self.features_sets)\n",
    "        return results\n",
    "\n",
    "\n",
    "def append(data:Dict[str, List[float]], key:str, value:float):\n",
    "    if key not in data:\n",
    "        data[key] = []\n",
    "    data[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from utils import estimator_helpers\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "N_SPLITS = [5,]\n",
    "OMICS = [\"__ALL__\", \"mutation\", \"cnv\", \"mirna\", \"rna\"]\n",
    "RANDOM_SEEDS = [0,42,21]\n",
    "FEATURES_NUMS = [10,25,100]\n",
    "i = 0\n",
    "I =  len(datasets) * len(OMICS) * len(N_SPLITS)\n",
    "\n",
    "for ds_name, df in datasets.items():    \n",
    "    y = df.values[:,0]\n",
    "    \n",
    "    for omics in OMICS:\n",
    "        X = get_X(df.iloc[:,1:], omics)\n",
    "\n",
    "        for n_splits in N_SPLITS:\n",
    "            selectors = estimator_helpers.create_selectors(estimators, X, y, FEATURES_NUMS, train_size=(1.-1./n_splits))\n",
    "            results = { name: CVResult(X.shape[1]) for name in selectors }\n",
    "\n",
    "            for random_seed in RANDOM_SEEDS:\n",
    "                skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "                    \n",
    "                for train_index, test_index in skf.split(X, y):\n",
    "                    X_train, y_train = X[train_index], y[train_index]\n",
    "                    X_test, y_test = X[test_index], y[test_index]\n",
    "                    \n",
    "                    for name, selector in selectors.items():\n",
    "                        # calculate results on this split for every estimator/selector\n",
    "                        result = results[name]\n",
    "                        selector.fit(X_train, y_train)\n",
    "                        selected_features_indexes = selector.get_support(indices=True)\n",
    "                        result.add_feature_set(set(selected_features_indexes))\n",
    "                        result.evaluate(\"train\", y_train, selector.estimator_.predict(X_train))\n",
    "                        result.evaluate(\"test\", y_test, selector.estimator_.predict(X_test))\n",
    "            i+=1\n",
    "            print(f\"Results {i}/{I} for {ds_name} {omics} and {n_splits}-fold cross validation:\")\n",
    "            \n",
    "            for name, result in results.items():\n",
    "                r = result.summary()\n",
    "                #print(f\"{name:5} : \", r)\n",
    "                append(data, \"cv-folds\", n_splits)\n",
    "                append(data, \"dataset\", ds_name)\n",
    "                append(data, \"estimator\", name)\n",
    "                append(data, \"omics\", omics_str(omics))\n",
    "                for key, value in r.items():\n",
    "                    append(data, key, value)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"results/r_{datetime.today().strftime('%Y%m%d_%H%M')}.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils import estimator_helpers\n",
    "\n",
    "df = datasets[\"COAD\"]\n",
    "yy = df.values[:,0]\n",
    "\n",
    "for omics in (\"__ALL__\", \"mutation\", \"cnv\", \"mirna\", \"rna\"):\n",
    "    X = get_X(df.iloc[:,1:], omics)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    selected_index, _ = next(skf.split(X, yy))\n",
    "    X, y = X[selected_index], yy[selected_index]\n",
    "\n",
    "    for n_features in (10, 25, 100):\n",
    "        C = estimator_helpers.match_C_to_number_of_features(\n",
    "            LinearSVC,\n",
    "            n_features,\n",
    "            X, y,\n",
    "            estimator_params = {'penalty':'l1', 'dual':False, 'max_iter':100000},\n",
    "            max_c = 5.0\n",
    "        )\n",
    "        print(f\"SVM {omics:10} {n_features:4} {C}\")\n",
    "\n",
    "        C = estimator_helpers.match_C_to_number_of_features(\n",
    "            LogisticRegression,\n",
    "            n_features,\n",
    "            X, y,\n",
    "            estimator_params = {'penalty':'l1', 'solver':'liblinear', 'max_iter':100000},\n",
    "            max_c = 5.0\n",
    "        )\n",
    "        print(f\"LR  {omics:10} {n_features:4} {C}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
